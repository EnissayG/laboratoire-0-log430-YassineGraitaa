# üìò Rapport final ‚Äì Laboratoire 5 (LOG430 - √ât√© 2025)

## 1. Introduction

Ce rapport retrace l‚Äô√©volution du projet multi-magasins r√©alis√© dans le cadre du cours LOG430, lors de l‚Äô√©t√© 2025. √Ä travers ce cinqui√®me laboratoire, nous avons entrepris la migration compl√®te d‚Äôun syst√®me monolithique, initialement structur√© en 3 tiers, vers une architecture orient√©e microservices. Cette transformation vise √† mieux r√©pondre aux exigences de flexibilit√©, de scalabilit√© et de maintenabilit√©, tout en int√©grant des m√©canismes modernes d‚Äôobservabilit√© et de gestion de la charge.

L‚Äôarchitecture cible repose sur une s√©rie de microservices sp√©cialis√©s, chacun responsable d‚Äôun sous-domaine m√©tier : gestion des produits, du stock, des ventes, des clients, des magasins, du panier d‚Äôachat et du processus de validation de commande (checkout). Chacun de ces microservices est conteneuris√©, isol√©, et poss√®de sa propre base de donn√©es PostgreSQL. La communication entre les services s‚Äôeffectue via des appels HTTP, orchestr√©s par une API Gateway centralis√©e : **KrakenD**. Enfin, un m√©canisme de **load balancing** a √©t√© mis en place sur le `stock-service`, accompagn√© d‚Äôoutils d‚Äô**observabilit√©** comme **Prometheus** et **Grafana** pour le suivi en temps r√©el du comportement du syst√®me.

---

## 2. Objectifs et exigences

Le principal objectif p√©dagogique de ce laboratoire √©tait de pousser plus loin la mod√©lisation logicielle en abordant la complexit√© r√©elle d‚Äôune architecture distribu√©e. Contrairement aux laboratoires pr√©c√©dents centr√©s sur la s√©paration logique en trois couches (pr√©sentation, logique m√©tier, persistance), ce laboratoire introduit une fragmentation physique de l‚Äôapplication en plusieurs services autonomes. Cette d√©marche oblige √† penser la communication entre composants, la robustesse des int√©grations, la tol√©rance aux pannes, et les m√©canismes de supervision n√©cessaires √† une production viable.

Sur le plan fonctionnel, le syst√®me devait √™tre capable d‚Äôex√©cuter les op√©rations classiques d‚Äôun mini-syst√®me e-commerce : cr√©ation, mise √† jour et consultation des produits, gestion du stock par magasin, enregistrement des ventes, suivi des clients, gestion du panier d‚Äôachat, et processus de commande. Le tout devait fonctionner de mani√®re fluide et coh√©rente, m√™me en pr√©sence d‚Äôune charge r√©partie sur plusieurs instances de certains services critiques comme le `stock-service`.

Les exigences non fonctionnelles occupaient √©galement une place centrale. Il s‚Äôagissait notamment d‚Äôassurer une **scalabilit√© horizontale**, en instanciant plusieurs services identiques derri√®re un **proxy NGINX**. L‚Äôint√©gration de **Prometheus** permettait de collecter des m√©triques sur les temps de r√©ponse et les performances, tandis que **Grafana** offrait une visualisation conviviale de l‚Äô√©tat du syst√®me. D'autres aspects comme la **documentation Swagger**, la gestion centralis√©e des erreurs, et l‚Äôuniformisation des formats JSON contribuaient √† am√©liorer la qualit√© globale du produit livr√©, tant du point de vue technique que de l‚Äôexp√©rience d√©veloppeur.

---

## 3. Contexte

Le projet s‚Äôappuie sur des technologies modernes, accessibles et bien int√©gr√©es entre elles. Le langage Python, coupl√© √† **FastAPI**, a permis une construction rapide et lisible des diff√©rents services, tout en favorisant l‚Äôusage de standards comme OpenAPI pour la documentation et Pydantic pour la validation des donn√©es. Chaque service repose sur sa propre base de donn√©es **PostgreSQL**, ce qui renforce l‚Äôind√©pendance des modules et limite les effets de bord lors des d√©ploiements ou des pannes locales.

Tous les composants sont conteneuris√©s √† l‚Äôaide de **Docker**, permettant une orchestration simple via `docker-compose`. Cette approche facilite non seulement les tests locaux mais ouvre √©galement la porte √† un futur d√©ploiement dans des environnements cloud natifs. La **API Gateway KrakenD** joue un r√¥le fondamental : elle agit comme point d‚Äôentr√©e unique vers les microservices, filtre et r√©√©crit les requ√™tes, applique des r√®gles de quota, et centralise les logs.

Enfin, les interconnexions entre services ont √©t√© pens√©es de mani√®re explicite. Les appels HTTP entre les modules sont directs et bien d√©finis. √Ä titre d‚Äôexemple, la validation d‚Äôun panier implique un encha√Ænement d‚Äôop√©rations r√©parties entre les microservices `panier-service`, `stock-service`, et `ventes-service`, chacune jouant un r√¥le pr√©cis dans la transaction globale.

---

## 4. Architecture logique (Vue de d√©veloppement)

### Technologies utilis√©es
| Couches        | Composants                           |
|----------------|---------------------------------------|
| Frontend       | React.js                             |
| API Gateway    | KrakenD                              |
| Microservices  | FastAPI, Pydantic, PostgreSQL        |
| Observabilit√©  | prometheus_fastapi_instrumentator, Grafana |
| Orchestration  | Docker, Docker Compose               |

![alt text](image-9.png)

---

## 5. Architecture physique (Vue de d√©ploiement)

Tous les services sont conteneuris√©s et communiquent via le bridge `log430-network`. Le `stock-service` est r√©pliqu√© en deux instances, avec NGINX en frontal comme **load balancer**.

```
Utilisateur ‚Üí KrakenD ‚Üí Microservices (via r√©seau Docker)
                              ‚Üì
                ‚Ü™ Prometheus ‚Ü™ Grafana
```

![alt text](image-2.png)

---

## 6. Architecture des cas d‚Äôutilisation (Vue logique)

### Services principaux
- `produits-service` : CRUD Produits
- `magasin-service` : CRUD Magasins
- `stock-service` : consultation/modification du stock
- `panier-service` : gestion du panier utilisateur
- `checkout-service` : validation de commande
- `ventes-service` : enregistrement des ventes
![alt text](image-6.png)

![alt text](image-3.png)

![alt text](image-7.png)
![alt text](image-8.png)
---

## 7. Architecture des composants (Vue d‚Äôimpl√©mentation)

Chaque microservice est structur√© selon une architecture **3-tiers** :
- `routers/` (FastAPI endpoints)
- `services/` (logique m√©tier)
- `dao/` ou `repositories/` (acc√®s BD via SQLAlchemy)
- `models/` (ORM + Pydantic)

![alt text](image-5.png)
---

## 8. Vue des processus (Vue dynamique)

Les interactions entre services sont bas√©es sur des appels HTTP internes via leur nom DNS (ex: `http://produits-service:8000`). Les requ√™tes passent d‚Äôabord par KrakenD, qui applique le routing et le quota.

![alt text](image-10.png)

---

## 9. Observabilit√© & Load Balancing

- `stock-service` est dupliqu√© (`stock-service-1`, `stock-service-2`)
- `nginx` r√©partit la charge entre les deux via `upstream`
- `prometheus_fastapi_instrumentator` expose les m√©triques
- `Grafana` permet d‚Äôanalyser : temps de r√©ponse, charge, erreurs

---

## 10. S√©curit√© & throttling (KrakenD)

KrakenD applique une politique CORS et un **throttling** global :  
- `max_rate`: 5 requ√™tes/s
- `client_max_rate`: 2 requ√™tes/s par client

Impl√©ment√© via `github_com/devopsfaith/krakend/ratelimit`

---

## 11. Architectural Decision Records (ADR)

### ADR-001: Choix de l‚Äôarchitecture microservices

### Statut
Accept√©e ‚Äì 2025-07-16

### Contexte
Le syst√®me initial, construit dans les laboratoires pr√©c√©dents, suivait une architecture 3-tiers avec un backend FastAPI monolithique. Cependant, la complexit√© du domaine e-commerce (produits, stock, ventes, clients, panier, validation) justifie une s√©paration claire des responsabilit√©s. Le besoin de scalabilit√©, de r√©partition de charge, et de d√©ploiement ind√©pendant renforce cette n√©cessit√©.

### D√©cision
Nous avons choisi de migrer vers une **architecture microservices**, en d√©coupant l‚Äôapplication en services ind√©pendants :

- `produits-service`
- `stock-service` (x2, derri√®re un NGINX load balancer)
- `ventes-service`
- `magasin-service`
- `client-service`
- `panier-service`
- `checkout-service`
- Chaque service poss√®de sa propre base de donn√©es PostgreSQL.

Une **API Gateway** (KrakenD) centralise les appels et applique du throttling, des logs et des r√®gles de routage.

### Cons√©quences

#### ‚úÖ Positives
- Meilleure s√©paration des responsabilit√©s m√©tier
- D√©ploiement ind√©pendant de chaque service
- Scalabilit√© horizontale facilit√©e
- Facilit√© d‚Äôint√©gration avec des observateurs (Prometheus/Grafana)

#### ‚ùå N√©gatives
- Complexit√© accrue : orchestration Docker, configurations, surveillance
- Mont√©e en charge de la CI/CD
- Coh√©sion entre services √† maintenir manuellement (pas de service discovery automatis√©)

### Alternatives envisag√©es
- Garder un monolithe FastAPI mais avec modularisation stricte
- Utiliser une architecture hexagonale au lieu de microservices

### ADR-002: Choix de KrakenD comme API Gateway

#### Statut
Accept√©e ‚Äì 2025-07-16

#### Contexte
Une fois le syst√®me d√©coup√© en microservices, un besoin de centraliser les appels frontaux est apparu : pour uniformiser les URL, g√©rer le CORS, appliquer des quotas, et simplifier le point d‚Äôentr√©e du client.

#### D√©cision
Nous avons choisi **KrakenD** comme API Gateway pour son approche d√©clarative, sa l√©g√®ret√©, et sa capacit√© √† g√©rer :

- les r√®gles de routage vers les services
- le CORS, les quotas, et le throttling
- des logs structur√©s
- une configuration JSON simple √† int√©grer dans notre `docker-compose`

### Cons√©quences

#### ‚úÖ Positives
- D√©ploiement rapide et sans code (config JSON uniquement)
- Int√©gration naturelle avec Docker
- Compatible avec Prometheus et Grafana
- Bon support du load balancing (directement ou via NGINX interm√©diaire)

#### ‚ùå N√©gatives
- Moins dynamique qu‚Äôune gateway comme Kong ou Traefik (pas de service discovery)
- Gestion manuelle des chemins JSON pour chaque endpoint
- Pas de support avanc√© OAuth/JWT sans plugins additionnels

#### Alternatives envisag√©es
- Utiliser Traefik (plus flexible mais plus complexe √† configurer)
- D√©velopper une API gateway maison avec FastAPI (trop long pour le contexte du labo)


---

## 12. Difficult√©s rencontr√©es

- üêõ Probl√®mes de DNS Docker pour certains services (`no such host`)
- ‚ö†Ô∏è Erreurs de timeout `context deadline exceeded` corrig√©es via `depends_on` + `timeout` ajust√©
- üîÄ Probl√®mes de redirection NGINX vs KrakenD (ports, host, etc.)

---

## 13. Conclusion

Ce laboratoire a marqu√© une √©tape d√©cisive dans l‚Äô√©volution de notre syst√®me vers une architecture logicielle moderne, modulaire et robuste. En migrant d‚Äôun syst√®me 3-tiers vers une architecture microservices, nous avons pu :D√©coupler les responsabilit√©s m√©tier (produits, stock, ventes, clients, panier, checkout, etc.),Isoler les bases de donn√©es par domaine, favorisant la coh√©rence et la r√©silience,
Mettre en place une gateway API centralis√©e (KrakenD), facilitant l‚Äôuniformisation des appels clients,
Introduire la r√©partition de charge (load balancing) avec NGINX pour le service critique de stock,
Configurer une base pour l'observabilit√© via Prometheus et Grafana.

#### Difficult√©s rencontr√©es
Plusieurs d√©fis ont √©t√© surmont√©s tout au long de l‚Äôimpl√©mentation :
- La duplication de services pour le load balancing a n√©cessit√© une attention particuli√®re sur la configuration r√©seau (bridge, alias, ports), le docker-compose et le proxy NGINX.

- L'int√©gration de KrakenD a n√©cessit√© de comprendre sa syntaxe JSON, les r√®gles de routage, le CORS, le logging, et l‚Äôajout d‚Äôun quota (throttling).

- La coh√©sion interservices, via httpx en Python, a exig√© un design propre et r√©silient, surtout pour le microservice checkout-service qui interagit avec plusieurs services en cascade.

- La structure de projet et les chemins relatifs entre services, configurations et volumes a parfois caus√© des erreurs subtiles mais critiques (ex: mauvais volume mont√© ou chemin nginx erron√©).

- Le versioning des d√©pendances (ex: pydantic v2) a caus√© des conflits, comme le changement de orm_mode vers from_attributes, n√©cessitant une veille attentive.

#### Recommandations architecturales
Bas√© sur notre exp√©rience :

- Factoriser certains comportements transversaux (logs, erreurs, cache) dans des middlewares ou biblioth√®ques partag√©es entre microservices.

- Ajouter un service de discovery ou registry si le nombre de microservices continue √† cro√Ætre.

- Renforcer l'observabilit√© : exporter plus de m√©triques m√©tier dans Prometheus, cr√©er des alertes pertinentes.

- Pr√©voir l‚Äôusage de circuit breakers ou de timeouts explicites pour √©viter les effets en cascade en cas de panne.

- Envisager une authentification centralis√©e (OAuth2/JWT) au niveau de la gateway pour un contr√¥le d‚Äôacc√®s plus fin.

#### Bilan
Au final, cette migration nous a permis de mieux comprendre les b√©n√©fices concrets de l‚Äôapproche microservices : 
- scalabilit√©, ind√©pendance des d√©ploiements, robustesse, testabilit√©. Malgr√© une charge de configuration initiale √©lev√©e, les gains √† long terme justifient pleinement cette approche.

Ce projet a aussi permis de se familiariser avec des outils modernes de production comme Docker, KrakenD, Prometheus, NGINX, FastAPI, et l‚Äô√©criture de tests int√©gr√©s dans un contexte distribu√©.

Nous avons construit non seulement un syst√®me fonctionnel, mais √©galement une base solide pour des √©volutions futures r√©alistes dans un contexte e-commerce professionnel.