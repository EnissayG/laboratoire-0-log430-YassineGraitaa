## 1. Introduction

Ce rapport pr√©sente l'√©volution d'une application de gestion de commandes multi-magasins vers une architecture distribu√©e fond√©e sur les √©v√©nements. Ce travail s'inscrit dans le cadre du Laboratoire 7 du cours LOG430 ‚Äì Architecture logicielle (√ât√© 2025) √† l'√âTS.

Apr√®s avoir introduit des microservices avec orchestrateur (Lab 6), cette it√©ration vise √† remplacer le contr√¥le centralis√© par une coordination asynchrone entre services √† l‚Äôaide :
- d‚Äôun syst√®me de messagerie de type Pub/Sub (Redis Streams),
- d‚Äôun Event Store persistant,
- de vues s√©par√©es de lecture/√©criture (CQRS),
- et d‚Äôune saga chor√©graphi√©e pour la gestion des transactions distribu√©es.

L‚Äôapproche √©v√©nementielle adopt√©e permet une meilleure r√©silience, un d√©couplage fort entre services, une auditabilit√© compl√®te via les √©v√©nements, et une meilleure extensibilit√© fonctionnelle.


## 2. Sc√©nario m√©tier retenu

Le sc√©nario m√©tier choisi pour ce laboratoire repose sur un processus central du domaine e-commerce : le traitement d‚Äôune commande client √† partir d‚Äôun panier multi-produits, dans un syst√®me multi-magasins. Ce processus distribu√© implique plusieurs microservices, chacun responsable d‚Äôun sous-domaine m√©tier. Le client ajoute d‚Äôabord des produits √† son panier, puis soumet une commande. Cette action d√©clenche une s√©rie d‚Äôinteractions asynchrones entre services.

Concr√®tement, lorsqu‚Äôun client valide son panier, le `panier-service` publie un √©v√©nement m√©tier de type `CommandeCreee` sur un canal Redis Streams. Cet √©v√©nement d√©clenche alors une r√©action en cha√Æne, sans coordination centralis√©e : le `stock-service` tente de r√©server les quantit√©s demand√©es pour chaque produit. Si les quantit√©s sont suffisantes, il publie √† son tour un √©v√©nement `StockReserve`. Dans le cas contraire, il publie `StockIndisponible`, ce qui met fin pr√©matur√©ment √† la transaction.

Si le stock a √©t√© correctement r√©serv√©, le `client-service` est notifi√© et proc√®de au d√©bit du montant total de la commande. En cas de solde suffisant, il √©met l‚Äô√©v√©nement `PaiementAccepte`. Sinon, l‚Äô√©v√©nement `PaiementRefuse` est publi√©, d√©clenchant des actions de compensation (lib√©ration du stock r√©serv√©). Finalement, si le paiement est accept√©, le `ventes-service` enregistre la vente et publie l‚Äô√©v√©nement `VenteConfirmee`.

Chacune de ces √©tapes repose sur un m√©canisme Pub/Sub assurant un fort d√©couplage. Aucun service ne conna√Æt les services abonn√©s, ni n‚Äôattend de r√©ponse directe. Cette architecture permet une grande souplesse pour ajouter de nouveaux consommateurs (audit, notification, supervision) sans modifier la logique m√©tier existante. Tous les √©v√©nements sont parall√®lement persist√©s dans un `event-store`, ce qui permet leur relecture, la reconstruction d‚Äô√©tat √† partir de projections, et une auditabilit√© compl√®te.

Ce sc√©nario, bien que simple dans son d√©roulement, permet de d√©montrer la combinaison efficace de plusieurs concepts d‚Äôarchitecture logicielle moderne : la communication √©v√©nementielle, l‚ÄôEvent Sourcing, la s√©paration des responsabilit√©s (CQRS), et la coordination d√©centralis√©e des transactions (saga chor√©graphi√©e).


## 3. Architecture √©v√©nementielle globale

L‚Äôarchitecture du syst√®me repose d√©sormais sur un mod√®le √©v√©nementiel distribu√©, fond√© sur la publication et la consommation d‚Äô√©v√©nements m√©tier √† travers un bus de messages impl√©ment√© avec Redis Streams. Chaque microservice √©met ses propres √©v√©nements en r√©ponse √† une action m√©tier locale (par exemple : cr√©ation de commande, r√©servation de stock, acceptation de paiement), tout en s‚Äôabonnant √† certains √©v√©nements produits par d‚Äôautres services.

Ce mod√®le suit le paradigme Pub/Sub : les producteurs n‚Äôont pas connaissance des consommateurs, ce qui permet un couplage tr√®s faible entre services. Ainsi, il est possible d‚Äôajouter ou de retirer des consommateurs (ex. audit, notification) sans modifier la logique des producteurs. Cette souplesse est l‚Äôun des avantages majeurs d‚Äôune architecture fond√©e sur les √©v√©nements.

Les √©v√©nements sont s√©rialis√©s en JSON, enrichis de m√©tadonn√©es (horodatage, type, ID d‚Äôagr√©gat, source), puis publi√©s dans des **streams Redis** nomm√©s de fa√ßon explicite (`commande.evenements`, `paiement.evenements`, etc.). Les microservices consomment ces √©v√©nements via des **groupes de consommateurs**, assurant ainsi une gestion de la concurrence, des red√©liveries et une r√©partition du traitement.

En compl√©ment de la propagation des √©v√©nements, un composant `event-store` a √©t√© introduit pour assurer une **persistance durable** de tous les √©v√©nements m√©tiers. Il stocke chaque √©v√©nement dans une base PostgreSQL, avec un endpoint permettant leur relecture et leur projection. Ce m√©canisme d‚Äô**Event Sourcing** permet de reconstruire l‚Äô√©tat courant d‚Äôun agr√©gat (commande, panier, etc.) √† tout moment, en rejouant les √©v√©nements le concernant.

Certains services adoptent en plus le mod√®le **CQRS** : ils s√©parent leurs op√©rations de lecture (projection, consultation) des op√©rations d‚Äô√©criture (commande, √©mission d‚Äô√©v√©nement). Cela permet de disposer de mod√®les de lecture optimis√©s, par exemple des vues index√©es ou mat√©rialis√©es, tout en conservant une logique m√©tier pure dans la partie √©criture.

La communication inter-service est donc asynchrone, orient√©e √©v√©nement, persistante et extensible. L‚Äôinfrastructure technique repose sur Docker Compose, avec Prometheus pour l‚Äôobservabilit√©, Grafana pour la visualisation des m√©triques, et un syst√®me de monitoring qui expose des compteurs Prometheus au niveau de chaque service.

![alt text](image.png)

## 4. Diagramme de s√©quence ‚Äì Saga chor√©graphi√©e

La coordination de la commande ne repose plus sur un orchestrateur central (comme dans le laboratoire pr√©c√©dent), mais sur une **saga chor√©graphi√©e**. Dans ce mod√®le, chaque microservice r√©agit √† des √©v√©nements, d√©clenche des actions locales, puis publie √† son tour un nouvel √©v√©nement. Ainsi, l‚Äô√©tat de la commande progresse de mani√®re distribu√©e, chaque service √©tant responsable de sa propre logique de traitement et de compensation.

Le processus est initialis√© par le `panier-service`, qui publie un √©v√©nement `CommandeCreee` lorsque le client valide son panier. Cet √©v√©nement est consomm√© par le `stock-service`, qui tente de r√©server les produits n√©cessaires. Si le stock est suffisant, il √©met un √©v√©nement `StockReserve`, permettant au `client-service` de proc√©der au paiement. Si le solde du client est ad√©quat, ce dernier publie `PaiementAccepte`, ce qui permet au `ventes-service` d‚Äôenregistrer la vente et de cl√¥turer la transaction.

√Ä tout moment, un service peut constater un √©chec (stock insuffisant, solde insuffisant) et publier un √©v√©nement d‚Äô√©chec (`StockIndisponible`, `PaiementRefuse`). Les services ayant d√©j√† effectu√© des actions peuvent alors effectuer des **compensations locales** : lib√©ration de stock, remboursement du client, annulation de vente.

Ce mod√®le de coordination par √©v√©nements rend le syst√®me plus r√©silient aux pannes partielles, plus flexible √† √©tendre, et plus simple √† monitorer via les √©v√©nements √©mis.

![alt text](image-1.png)

## 4.1 Contexte et cas d'utilisation

Le syst√®me multi-magasins repose sur des interactions entre plusieurs acteurs (employ√©, client, observateur Prometheus) et des cas d‚Äôutilisation m√©tiers vari√©s : gestion de produits, de stock, de clients, de ventes, et coordination de commandes via une saga.

Le diagramme ci-dessous pr√©sente le contexte d‚Äôutilisation g√©n√©ral du syst√®me, avec les cas d‚Äôusage associ√©s.

![alt text](image-4.png)

Voici une vue d√©taill√©e des cas d‚Äôutilisation, regroup√©s par domaine fonctionnel. On y retrouve la validation de commande, les mises √† jour de stock, la cr√©ation de clients et la gestion de la saga.

![alt text](image-5.png)


## 5. ADR 1 ‚Äì Choix de Redis Streams comme syst√®me de messagerie Pub/Sub

### Contexte

Dans le cadre du Laboratoire 7, le projet devait impl√©menter une communication √©v√©nementielle entre microservices √† l‚Äôaide d‚Äôun syst√®me de messagerie. Plusieurs options √©taient possibles, notamment Kafka, RabbitMQ, NATS, ou Redis Streams. Il √©tait crucial de choisir une solution compatible avec Docker Compose, l√©g√®re √† d√©ployer, et suffisamment puissante pour supporter les sch√©mas de type Pub/Sub avec gestion des groupes de consommateurs.

### D√©cision

Nous avons d√©cid√© d‚Äôutiliser **Redis Streams** comme m√©canisme principal de communication Pub/Sub entre microservices.

### Raisons

- **Simplicit√© d‚Äôint√©gration** : Redis est d√©j√† bien support√© dans l‚Äô√©cosyst√®me Python/FastAPI, et son usage ne n√©cessite pas de configuration complexe.
- **Support natif des streams** : Redis Streams fournit un mod√®le d‚Äôappend-only log avec gestion des groupes de consommateurs (`XGROUP`), accus√©s de r√©ception (`XACK`), reprise (`XREADGROUP`), etc.
- **L√©g√®ret√© et rapidit√© de d√©ploiement** : Redis fonctionne tr√®s bien dans Docker, sans overhead majeur, contrairement √† Kafka ou RabbitMQ qui n√©cessitent souvent plusieurs conteneurs pour fonctionner.
- **Performance raisonnable** : Redis Streams est adapt√© aux charges √©v√©nementielles mod√©r√©es, suffisantes pour un syst√®me acad√©mique ou de taille moyenne.
- **Support asynchrone** : La biblioth√®que `redis.asyncio` permet une consommation non-bloquante efficace dans un contexte `async def`.

### Alternatives consid√©r√©es

- **Apache Kafka** : bien plus robuste et adapt√© aux syst√®mes √† grande √©chelle, mais tr√®s lourd √† configurer dans un environnement local sans Confluent Platform. Id√©al en production, mais surdimensionn√© ici.
- **RabbitMQ** : tr√®s populaire pour les cas d‚Äôusage m√©tier classiques, mais n√©cessite un serveur AMQP d√©di√© et une configuration sp√©cifique pour les retries et dead-letter queues.
- **NATS / MQTT** : tr√®s performants, mais moins document√©s dans l‚Äô√©cosyst√®me FastAPI + SQL, et plus orient√©s IoT/messaging pur.

### Cons√©quences

- La solution est adapt√©e au contexte p√©dagogique et au besoin de coordination √©v√©nementielle du syst√®me.
- Les microservices peuvent √©changer des √©v√©nements de mani√®re fiable, rejouer des messages, ou les distribuer √† plusieurs consommateurs sans se conna√Ætre.
- En cas d‚Äô√©volution vers un usage √† grande √©chelle, une migration vers Kafka serait envisageable, Redis servant alors de prototype fonctionnel.

### Statut

**Accept√©e ‚Äì impl√©ment√©e dans tous les services √† travers Redis Streams**


---

## 5.1 Vue de d√©veloppement

Chaque microservice suit une structure modulaire bas√©e sur FastAPI. Le diagramme ci-dessous montre l‚Äôorganisation interne typique d‚Äôun microservice (`main.py`, routers, services, mod√®les, etc.).

![alt text](image-6.png)

Le diagramme suivant repr√©sente les **d√©pendances entre microservices**. Chaque service communique avec d‚Äôautres via appels HTTP ou √©v√©nements Redis. Cette vue permet de comprendre les liens techniques entre services.

![alt text](image-7.png)

---

## 5.2 Vue des processus

La vue processus permet de visualiser le d√©roulement des sc√©narios m√©tiers cl√©s (succ√®s, rollback, transitions d'√©tat). Voici les principaux diagrammes associ√©s :

### a) Validation de commande (checkout)

![alt text](image-8.png)

Ce diagramme montre le flux asynchrone entre les services `panier`, `stock`, `client` et `vente`, lors de la cr√©ation d‚Äôune commande.

### b) √âchec de paiement (rollback)

![alt text](image-9.png)

Ce diagramme illustre la compensation en cas de paiement refus√© (lib√©ration du stock, arr√™t de la vente).

### c) Machine d'√©tat de la saga

![alt text](image-10.png)

Ce diagramme d√©crit les diff√©rents √©tats d‚Äôune commande dans le cadre de la saga chor√©graphi√©e (`en_attente_stock`, `stock_reserve`, `paiement_refuse`, etc.).

---
## 5.3 Vue de d√©ploiement

Le syst√®me repose sur une infrastructure Docker avec plusieurs conteneurs : microservices FastAPI, bases PostgreSQL, Redis, Prometheus, Grafana et Krakend. La vue suivante montre le d√©ploiement global des composants.

![alt text](image-11.png)

## 6. ADR 2 ‚Äì Impl√©mentation de l‚ÄôEvent Store avec PostgreSQL

### Contexte

Dans le cadre de l‚Äôapproche Event Sourcing, il √©tait n√©cessaire d‚Äôimpl√©menter un composant `event-store` capable de stocker durablement tous les √©v√©nements m√©tier produits par les diff√©rents microservices. Ce composant devait √©galement permettre la relecture des √©v√©nements (replay), ainsi que la reconstruction de l‚Äô√©tat courant d‚Äôun agr√©gat m√©tier via une projection.

Il √©tait donc imp√©ratif de choisir une solution de stockage persistant, fiable, interrogeable, et facilement int√©grable avec les outils de l‚Äô√©cosyst√®me Python/FastAPI.

### D√©cision

Nous avons choisi d‚Äôutiliser **PostgreSQL** comme base de donn√©es pour impl√©menter l‚ÄôEvent Store, avec une API FastAPI exposant des endpoints REST pour l‚Äô√©criture et la lecture des √©v√©nements.

### Raisons

- **Fiabilit√© et robustesse** : PostgreSQL est une base ACID largement √©prouv√©e, adapt√©e au stockage de donn√©es s√©quentielles et historis√©es.
- **Requ√™tabilit√©** : Les √©v√©nements √©tant stock√©s sous forme de lignes JSON, il est facile d‚Äôeffectuer des projections ou des filtres via des requ√™tes SQL.
- **Int√©gration rapide** : PostgreSQL est d√©j√† utilis√© dans d'autres microservices du syst√®me, ce qui simplifie son d√©ploiement avec Docker.
- **Pas de d√©pendance √† des outils tiers** : Contrairement √† Kafka (avec sa propre r√©tention de log) ou √† MongoDB (n√©cessitant un mod√®le de document), PostgreSQL reste simple √† configurer et document√© dans le contexte FastAPI + SQLAlchemy.
- **Contr√¥le sur la structure** : Le sch√©ma des √©v√©nements inclut des champs typ√©s (type, source, timestamp, agr√©gat, donn√©es JSON), ce qui permet d‚Äôassurer une structure coh√©rente dans l‚Äôensemble du syst√®me.


## 6.1 Structure technique ‚Äì Event Store

Le microservice `event-store` joue un r√¥le cl√© dans l‚Äôapproche Event Sourcing. Il stocke tous les √©v√©nements m√©tiers dans PostgreSQL, permet leur relecture et reconstruit l‚Äô√©tat projet√© d‚Äôun agr√©gat via `/projections/{id}`.

Le diagramme ci-dessous illustre l‚Äôarchitecture interne de ce microservice.

![alt text](image-12.png)
---

## 6.2 Vue logique (bonus)

Une vue logique compl√©mentaire permet de visualiser les **classes m√©tiers** du domaine (Commande, Produit, Client, etc.) et leurs attributs. Elle aide √† mieux comprendre la structure s√©mantique des objets manipul√©s dans les √©v√©nements.

![alt text](image-13.png)

### Alternatives consid√©r√©es

- **Apache Kafka comme Event Store** : possible via les logs Kafka, mais n√©cessite un connecteur et une infrastructure plus lourde pour la persistance longue dur√©e.
- **MongoDB** : adapt√© aux documents JSON, mais moins robuste pour les projections complexes ou les relations fortes.
- **Fichiers plats (JSONLines)** : simple mais non scalable, non interrogeable facilement, et peu r√©silient.

### Cons√©quences

- Tous les √©v√©nements m√©tier (commande, stock, paiement, vente) sont persist√©s avec horodatage, source et ID d‚Äôagr√©gat.
- Un endpoint `/events/` permet l‚Äô√©criture via POST, tandis que `/projections/{aggregate_id}` permet de reconstruire un √©tat projet√© √† la vol√©e.
- Il est possible de rejouer les √©v√©nements pour un agr√©gat, d‚Äôenrichir les projections, ou d‚Äôexporter les √©v√©nements √† des fins d‚Äôanalyse.
- En cas d‚Äô√©volution du projet, une migration vers Kafka ou EventStoreDB serait envisageable avec adaptation minimale.

### Statut

**Accept√©e ‚Äì Impl√©ment√©e dans le microservice event-store**


## 7. Event Sourcing et Projections

L‚Äôarchitecture √©v√©nementielle mise en place repose sur un principe fondamental : chaque changement d‚Äô√©tat m√©tier est repr√©sent√© par un √©v√©nement immuable, enregistr√© dans un journal d‚Äô√©v√©nements (Event Store). Plut√¥t que de stocker uniquement l‚Äô√©tat courant d‚Äôun objet m√©tier (par exemple une commande ou un panier), le syst√®me conserve toute la s√©quence des √©v√©nements qui ont men√© √† cet √©tat.

Chaque √©v√©nement est encod√© en JSON, enrichi de m√©tadonn√©es structur√©es (type, source, timestamp, ID d‚Äôagr√©gat), puis stock√© dans une table relationnelle PostgreSQL. Ce m√©canisme d‚Äô**Event Sourcing** offre plusieurs avantages : auditabilit√©, tra√ßabilit√© compl√®te, possibilit√© de rejouer le pass√©, et reconstruction dynamique de l‚Äô√©tat.

Le microservice `event-store` expose deux endpoints REST :

- `POST /events/` : permet de persister un √©v√©nement m√©tier via un sch√©ma structur√© `EvenementIn`. Ce endpoint est invoqu√© par les producteurs d‚Äô√©v√©nements, notamment dans le cadre de la saga chor√©graphi√©e (commande, paiement, vente).
- `GET /events/projections/{aggregate_id}` : permet de rejouer tous les √©v√©nements associ√©s √† un agr√©gat donn√© et de reconstruire son √©tat courant.

La logique de projection repose sur un service `reconstruire_etat(aggregate_id)`, qui r√©cup√®re les √©v√©nements dans l‚Äôordre chronologique et les applique √† une structure Python (dictionnaire mutable repr√©sentant l‚Äô√©tat agr√©g√©). Ce m√©canisme de **read model reconstruit √† la vol√©e** permet de g√©n√©rer des repr√©sentations l√©g√®res, coh√©rentes et v√©rifiables sans cr√©er de nouvelle base de donn√©es d√©di√©e.

Par exemple, pour une commande identifi√©e par `cmd-1234`, le replay d‚Äô√©v√©nements tels que `CommandeCreee`, `StockReserve`, `PaiementAccepte` et `VenteConfirmee` permet de g√©n√©rer un √©tat final contenant tous les produits command√©s, le client associ√©, le statut, le montant total, et l‚Äôissue de la transaction.

Ce m√©canisme offre ainsi une **vue temporelle explicite** de chaque transaction m√©tier, ce qui est particuli√®rement utile en contexte distribu√© o√π l‚Äô√©tat est diss√©min√© entre plusieurs microservices. En cas d‚Äôerreur, il est √©galement possible de comparer la projection avec les journaux ou de rejouer une s√©quence d‚Äô√©v√©nements pour diagnostiquer un comportement inattendu.

## 8. S√©paration CQRS (Command Query Responsibility Segregation)

Dans l‚Äôarchitecture mise en place, le mod√®le CQRS est appliqu√© de mani√®re cibl√©e pour s√©parer les responsabilit√©s de modification d‚Äô√©tat (commandes) et de consultation (requ√™tes). Cette s√©paration s‚Äôappuie sur le fait que les besoins techniques, fonctionnels et de performance sont tr√®s diff√©rents selon qu‚Äôun service manipule une commande ou interroge un √©tat projet√©.

Les commandes sont g√©r√©es de mani√®re classique via des endpoints REST expos√©s par les microservices m√©tiers (`POST /checkout`, `POST /paiement`, etc.). Ces commandes d√©clenchent des √©v√©nements m√©tier (`CommandeCreee`, `PaiementAccepte`, `VenteConfirmee`) qui sont publi√©s sur le bus Redis Streams. Ces √©v√©nements sont ensuite stock√©s de mani√®re persistante dans l‚ÄôEvent Store.

La lecture, quant √† elle, s‚Äôappuie sur des **vues projet√©es** construites √† partir de la relecture des √©v√©nements. Le microservice `event-store` fournit ainsi un point d‚Äôentr√©e de type `GET /projections/{aggregate_id}`, qui permet de reconstruire √† la vol√©e l‚Äô√©tat d‚Äôun agr√©gat (commande, panier, etc.) sans requ√™ter directement les bases m√©tiers des microservices producteurs.

Cette s√©paration permet plusieurs b√©n√©fices concrets :
- **Performance** : les lectures sont simplifi√©es, centralis√©es, et ne n√©cessitent pas d‚Äôagr√©ger dynamiquement les r√©ponses de plusieurs services.
- **R√©silience** : m√™me en cas de panne d‚Äôun service m√©tier (ex. `ventes-service`), l‚Äô√©tat d‚Äôune commande peut √™tre reconstitu√© de mani√®re autonome √† partir des √©v√©nements enregistr√©s.
- **Auditabilit√©** : les vues projet√©es sont d√©riv√©es d‚Äô√©v√©nements immuables, ce qui assure leur coh√©rence et permet une v√©rification facile en cas de litige ou d‚Äôincident.

Dans une version √©tendue, ces vues pourraient √™tre mat√©rialis√©es dans une base d√©di√©e, ou optimis√©es pour la recherche (indexation, cache Redis, etc.). Toutefois, dans ce laboratoire, la projection √† la vol√©e s‚Äôest r√©v√©l√©e suffisante et efficace pour d√©montrer le mod√®le CQRS, tout en limitant la complexit√© technique.


## 9. Observabilit√©

L‚Äôun des enjeux critiques d‚Äôune architecture distribu√©e fond√©e sur les √©v√©nements est la capacit√© √† comprendre, diagnostiquer et superviser le comportement global du syst√®me. Pour cela, l‚Äôobservabilit√© a √©t√© int√©gr√©e de mani√®re syst√©matique dans chaque microservice, √† l‚Äôaide de **Prometheus** pour la collecte des m√©triques, et **Grafana** pour la visualisation et l‚Äôanalyse.

Chaque microservice expose un endpoint `/metrics`, instrument√© via la biblioth√®que `prometheus_fastapi_instrumentator`. Ce middleware collecte des donn√©es techniques (latence, nombre de requ√™tes, erreurs HTTP) ainsi que des **m√©triques m√©tiers personnalis√©es** sp√©cifiques au sc√©nario √©v√©nementiel. Par exemple :

- `event_store_events_total{event_type="CommandeCreee", source="panier-service"}`  
  ‚Üí Compte le nombre d‚Äô√©v√©nements persist√©s par type et par origine.
- `commande_etat_total{etat="PaiementRefuse"}`  
  ‚Üí Suit la r√©partition des commandes par √©tat dans la machine √† √©tats distribu√©e.
- `saga_commande_succes_total` / `saga_commande_echec_total`  
  ‚Üí Compte les sagas r√©ussies vs √©chou√©es.
- `commande_latence_ms`  
  ‚Üí Histogramme de latence entre l‚Äô√©mission et la consommation d‚Äôun √©v√©nement.

Ces m√©triques sont r√©cup√©r√©es par Prometheus √† intervalle r√©gulier, puis affich√©es dans plusieurs **dashboards Grafana** configur√©s pour ce laboratoire. Deux types de tableaux de bord ont √©t√© con√ßus :

- **Dashboard g√©n√©ral d'activit√©** : flux d‚Äô√©v√©nements, nombre total d‚Äô√©v√©nements par service, latence moyenne, volume par topic Redis.
![alt text](image-2.png)
- **Dashboard saga** : suivi d√©taill√© des commandes en cours, taux de succ√®s/√©chec des transactions, m√©triques d‚Äô√©chec par service impliqu√© (stock, paiement, vente).
![alt text](image-3.png)

Ces tableaux offrent une visibilit√© compl√®te sur le comportement du syst√®me en production, et permettent d‚Äôidentifier rapidement les goulets d‚Äô√©tranglement, erreurs syst√©matiques, ou instabilit√©s.


## 10. Tests et R√©silience

Pour valider le bon fonctionnement de l‚Äôarchitecture √©v√©nementielle et de la coordination distribu√©e, plusieurs sc√©narios de tests ont √©t√© mis en place, incluant des cas de succ√®s et d‚Äô√©checs partiels. Ces tests ont permis de v√©rifier √† la fois la robustesse de la saga chor√©graphi√©e et la r√©activit√© des services √† diff√©rents √©v√©nements.

### Sc√©nario de succ√®s

Un test de bout en bout a √©t√© r√©alis√© √† l‚Äôaide de Postman ou via appel direct HTTP :
1. Un client ajoute plusieurs produits √† son panier (`panier-service`).
2. Il valide la commande, ce qui publie un √©v√©nement `CommandeCreee`.
3. Le `stock-service` r√©serve les produits ‚Üí `StockReserve`.
4. Le `client-service` valide le paiement ‚Üí `PaiementAccepte`.
5. Le `ventes-service` enregistre la vente ‚Üí `VenteConfirmee`.

La relecture de la commande via `/projections/{aggregate_id}` confirme la bonne propagation des √©v√©nements et l‚Äô√©tat final `VenteConfirmee`.

### Sc√©narios d‚Äô√©checs simul√©s

Des cas d‚Äô√©chec volontaire ont √©t√© introduits pour tester la **compensation** :
- **Stock insuffisant** : si la quantit√© en stock est inf√©rieure √† la demande, un √©v√©nement `StockIndisponible` est publi√©. Aucun paiement n‚Äôest d√©clench√©, et la commande reste incompl√®te.
- **Solde client insuffisant** : un montant volontairement insuffisant a √©t√© d√©fini pour le client. Le `client-service` publie alors `PaiementRefuse`, ce qui d√©clenche une **lib√©ration du stock** via un √©v√©nement compensatoire.
- **Interruption r√©seau ou plantage d‚Äôun service** : en arr√™tant manuellement un conteneur Docker (`ventes-service`), le reste de la cha√Æne continue de fonctionner. La r√©silience est assur√©e par le fait que l‚Äô√©v√©nement reste disponible dans Redis jusqu‚Äô√† sa consommation.

### R√©sultats

Les tests ont confirm√© :
- L‚Äôind√©pendance des services gr√¢ce au mod√®le Pub/Sub.
- La possibilit√© de traiter des commandes en parall√®le sans conflits.
- La robustesse du syst√®me en cas d‚Äôerreur, avec compensation ad√©quate.
- La tra√ßabilit√© compl√®te via les √©v√©nements stock√©s et les m√©triques expos√©es.

## 11. √âchantillons d‚Äô√©v√©nements, logs et projections

Afin d‚Äôillustrer le comportement de l‚Äôarchitecture √©v√©nementielle et de la saga chor√©graphi√©e, plusieurs extraits ont √©t√© collect√©s durant les tests. Ces donn√©es montrent √† la fois le contenu des √©v√©nements publi√©s, la mani√®re dont les logs structur√©s sont g√©n√©r√©s par les microservices, et le r√©sultat des projections depuis l‚ÄôEvent Store.

### üìå √âv√©nement m√©tier ‚Äì `CommandeCreee`

```json
{
  "event_type": "CommandeCreee",
  "aggregate_id": "cmd-1234",
  "timestamp": "2025-08-01T15:42:17.123Z",
  "source": "panier-service",
  "data": {
    "client_id": 42,
    "produits": [
      { "produit_id": 1, "quantite": 2, "sous_total": 10.0 },
      { "produit_id": 5, "quantite": 1, "sous_total": 5.0 }
    ],
    "total": 15.0
  }
}
```

### üìå Log structur√© ‚Äì R√©servation de stock r√©ussie

```log
[stock-service] Stock r√©serv√© pour commande cmd-1234
√âv√©nement publi√© : StockReserve
D√©tails : {"produits": [...], "total": 15.0, "client_id": 42}
```

### üìå Log structur√© ‚Äì Paiement refus√© et compensation

```log
[client-service] Paiement refus√© pour client 42, montant : 15.0
√âv√©nement publi√© : PaiementRefuse
[stock-service] Stock lib√©r√© pour commande cmd-1234 suite √† √©chec de paiement
```

### üìå Projection d‚Äôune commande (`/events/projections/cmd-1234`)

```json
{
  "client_id": 42,
  "produits": [
    { "produit_id": 1, "quantite": 2, "sous_total": 10.0 },
    { "produit_id": 5, "quantite": 1, "sous_total": 5.0 }
  ],
  "total": 15.0,
  "statut": "PaiementRefuse"
}
```

### üìå R√©silience constat√©e

M√™me en cas d‚Äôinterruption temporaire du `ventes-service`, la commande reste dans un √©tat coh√©rent. D√®s red√©marrage du service, les √©v√©nements en attente sont consomm√©s (`xreadgroup` Redis), garantissant **l‚Äôexact-once processing** gr√¢ce √† l‚Äôacknowledgement (`XACK`).

Ces extraits d√©montrent que chaque service produit des logs exploitables, que les √©v√©nements sont structur√©s et tra√ßables, et que l‚Äô√©tat m√©tier peut √™tre reconstitu√© de mani√®re fiable.

## 12. Conclusion critique

Ce laboratoire a permis de faire √©voluer une architecture de microservices vers un mod√®le √©v√©nementiel avanc√©, int√©grant les concepts de Pub/Sub, Event Sourcing, CQRS et saga chor√©graphi√©e. Il a illustr√© concr√®tement les b√©n√©fices li√©s au d√©couplage, √† la r√©silience et √† la scalabilit√©, tout en imposant une rigueur accrue dans la gestion des √©tats et des erreurs.

La transition vers une coordination par √©v√©nements, sans orchestrateur central, a exig√© une mod√©lisation rigoureuse du flux m√©tier et des √©v√©nements publi√©s √† chaque √©tape. La saga chor√©graphi√©e s‚Äôest r√©v√©l√©e particuli√®rement efficace pour g√©rer des transactions distribu√©es complexes, tout en permettant une compensation asynchrone robuste.

L‚Äôintroduction d‚Äôun Event Store ind√©pendant a renforc√© la transparence et l‚Äôauditabilit√© du syst√®me. La logique de relecture d‚Äô√©v√©nements pour reconstruire un √©tat m√©tier √† partir de son historique ouvre la voie √† des usages plus avanc√©s, comme la r√©tro-analyse, le versionnement d‚Äô√©tats, ou la migration de logique m√©tier dans le temps.

La s√©paration CQRS a apport√© de la clart√© conceptuelle, en distinguant clairement les responsabilit√©s de traitement et de lecture. Combin√©e √† une projection l√©g√®re, elle permet de construire des vues optimis√©es, sans coupler directement les services producteurs.

L‚Äôobservabilit√© a jou√© un r√¥le essentiel dans le d√©bogage et l‚Äôanalyse du syst√®me. Les m√©triques expos√©es (latence, volumes, erreurs) ont permis de diagnostiquer rapidement les goulets d‚Äô√©tranglement ou les d√©faillances de consommation.

En contrepartie, cette architecture induit une complexit√© sup√©rieure : gestion des duplications, ordering partiel des √©v√©nements, logique idempotente, outillage de test plus lourd. Des aspects comme la s√©curit√©, la gestion des erreurs silencieuses ou la r√©silience aux pannes r√©seau m√©riteraient d‚Äô√™tre renforc√©s dans une version de production.

Ce projet constitue n√©anmoins une d√©monstration concr√®te de l‚Äôint√©r√™t des architectures √©v√©nementielles dans les syst√®mes distribu√©s modernes. Il offre une base solide pour approfondir des th√©matiques comme les brokers distribu√©s (Kafka), le versionnement d‚Äô√©v√©nements, ou encore l‚Äôint√©gration avec des outils de monitoring centralis√©s (ELK stack, OpenTelemetry).

En r√©sum√©, cette exp√©rience met en lumi√®re l‚Äô√©quilibre n√©cessaire entre flexibilit√© architecturale, r√©silience technique et complexit√© ma√Ætris√©e.
